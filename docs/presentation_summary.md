# 🎬 팀 발표 자료: Graph RAG Recommendation 최적화 보고서

## 1. 🚨 문제 해결: GNN 학습 오류 수정
### 현상
- 초기 `gnn학습.ipynb` 실행 시, 모든 영화의 임베딩이 0 또는 매우 유사한 값으로 수렴.
- 결과적으로 `추천.ipynb`에서 모든 영화 간 유사도가 0.99로 측정되어 변별력 상실.

### 원인
- 학습 코드 내 손실 함수(Loss Function)가 `MSELoss(output, 0)`으로 설정되어 있어, 모델이 **"모든 값을 0으로 만드는 것"**을 목표로 학습함.

### 해결
- **Contrastive Learning (대조 학습)** 도입 (`gnn_train_corrected.py`)
- **Positive Pairs:** 같은 영화 내 인접 윈도우끼리 가깝게 학습.
- **Negative Pairs:** 다른 윈도우와는 멀어지도록 학습.
- **결과:** 정상적인 임베딩(`sw_embeddings.npy`) 생성 완료 및 추천 변별력 확보.

---

## 2. ⚡️ 성능 최적화 (핵심 성과)
기존 23초가 걸리던 추천 프로세스를 두 가지 트랙으로 최적화하여 구현했습니다.

### 🅰️ Track A: 극한의 속도 (Cached Approach)
- **파일:** `fast_recommendation.py`
- **방식:** 모든 영화의 연결 관계와 추천 사유를 미리 계산하여 파일(`movie_logic_cache.json`)로 저장.
- **성능:** **0.004초** (즉시 응답) 🚀
- **활용:** 실시간성이 중요하고 데이터 변경이 잦지 않은 메인 서비스에 적합.

### 🅱️ Track B: 논문 완벽 재현 (Real-time K-RagRec)
- **파일:** `k_rag_rec.py`
- **방식:** 논문(`K-RagRec`)의 구조를 그대로 따름. (Semantic Search → Sub-graph Retrieval → LLM Inference)
- **최적화:**
    - 초기 실행 시 17초 소요 (GPT-4o의 긴 응답 생성 때문).
    - **프롬프트 엔지니어링**을 통해 응답 길이를 제어(20단어 제한).
    - 최종 성능: **7.6초** (약 2.2배 가속) ⚡️
- **활용:** 사용자의 복잡한 질의나 새로운 데이터에 대한 실시간 추론이 필요한 경우 사용.

---

## 3. 🛠️ 기타 개선 사항
- **보안 강화:** 소스코드 내 하드코딩된 API 키 제거 및 `.env` 환경 변수 적용.
- **호환성 해결:** Mac 환경에서의 OpenMP 라이브러리 충돌 문제(`libomp`) 해결 (`KMP_DUPLICATE_LIB_OK=True`).
- **Git 동기화:** 모든 스크립트, 데이터, 문서(`walkthrough.md`)를 GitHub 리포지토리(`graphrag_recommendation`)에 업로드 완료.

## 4. 🏁 결론
> "우리는 GNN 학습 오류를 정상화하고, 상황에 따라 **0.004초(속도 중심)**와 **7초(유연성 중심)** 모델을 선택적으로 사용할 수 있는 **하이브리드 추천 시스템**을 구축했습니다."
