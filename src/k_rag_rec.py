import os
from dotenv import load_dotenv
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
import torch
import numpy as np
import faiss
import openai
from collections import defaultdict
from neo4j import GraphDatabase
import time

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(dotenv_path="../.env")

# --- ì„¤ì • ---
# 1. Neo4j & OpenAI
URI = "neo4j+ssc://2bdf163a.databases.neo4j.io:7687"
AUTH = ("neo4j", "dVRqLgBpDBT3tP37uYphK_zFZRjBHRizDVvRc4LCJRg")
api_key = os.getenv("OPENAI_API_KEY")

# 2. ë¦¬ì†ŒìŠ¤ ë¡œë“œ
print("ğŸ”„ Loading resources (Embeddings & Graph Data)...")
sw_embeddings = np.load("../data/sw_embeddings.npy")
saved = torch.load("../data/full_graph.pt", weights_only=False)
node_meta = saved['node_meta']
NODE_TYPE_MAP = saved['NODE_TYPE_MAP']

# SceneWindow ì¸ë±ìŠ¤ ë§¤í•‘
sw_mask = (saved['data'].node_type == NODE_TYPE_MAP['SceneWindow'])
sw_indices = sw_mask.nonzero(as_tuple=True)[0]

movie_to_sw = defaultdict(list)
for idx in range(len(sw_indices)):
    meta = node_meta[sw_indices[idx].item()]
    movie_to_sw[meta['movie']].append(idx)

# ì˜í™”ë³„ ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚°
movie_centroids = {}
for m, indices in movie_to_sw.items():
    vecs = sw_embeddings[indices].astype(np.float32)
    movie_centroids[m] = np.mean(vecs, axis=0)

# FAISS ì¸ë±ìŠ¤ ë¹Œë“œ
movie_titles = list(movie_centroids.keys())
matrix = np.array([movie_centroids[t] for t in movie_titles], dtype=np.float32)
faiss.normalize_L2(matrix)
index = faiss.IndexFlatIP(256)
index.add(matrix)

# 3. K-RagRec êµ¬í˜„ (Real-time Graph Retrieval + LLM Reasoning)
def retrieve_knowledge_subgraph(driver, target_movie, candidates):
    """
    ë…¼ë¬¸ì˜ 'Knowledge Sub-graphs Retrieval' ë‹¨ê³„ êµ¬í˜„.
    target_movieì™€ candidate_movies ê°„ì˜ ì—°ê²° ê²½ë¡œ(Path)ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰.
    """
    subgraphs = {}
    
    with driver.session() as session:
        for candidate in candidates:
            # 2-hop ì´ìƒì˜ ê²½ë¡œ íƒìƒ‰ (ë…¼ë¬¸ì—ì„œë„ Multi-hop Reasoning ê°•ì¡°)
            query = """
            MATCH (m1:Movie {title: $t})-[:HAS_WINDOW]->(sw1:SceneWindow)
            MATCH (m2:Movie {title: $c})-[:HAS_WINDOW]->(sw2:SceneWindow)
            MATCH p = (sw1)-[*1..2]-(sw2)
            RETURN [n in nodes(p) | coalesce(n.name, labels(n)[0])] as path
            LIMIT 5
            """
            result = session.run(query, t=target_movie, c=candidate).data()
            
            # ê²½ë¡œë¥¼ í…ìŠ¤íŠ¸í™” (Graph-to-Text)
            paths_text = []
            for record in result:
                path = " -> ".join(record['path'])
                paths_text.append(path)
            
            subgraphs[candidate] = paths_text
            
    return subgraphs

def generate_recommendation_with_llm(target_movie, subgraphs):
    """
    ë…¼ë¬¸ì˜ 'Knowledge-augmented Recommendation' ë‹¨ê³„ êµ¬í˜„.
    LLMì—ê²Œ ê·¸ë˜í”„ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ê²Œ í•¨.
    """
    client = openai.OpenAI(api_key=api_key)
    
    # Context êµ¬ì„±
    context_text = f"Target Movie: {target_movie}\n\n"
    for movie, paths in subgraphs.items():
        context_text += f"Candidate: {movie}\n"
        context_text += "  - Relationships:\n"
        for p in paths:
             context_text += f"    * {p}\n"
        context_text += "\n"
        
    prompt = f"""
    You are a recommendation engine. 
    User watched '{target_movie}'.
    Based on these retrieved paths:
    {context_text}
    
    Recommend each candidate in ONE short sentence (max 20 words). 
    Do NOT write intro/outro. Just list the movies and reasons.
    """
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )
    
    return response.choices[0].message.content

def run_k_rag_rec(target_movie):
    start_time = time.time()
    print(f"ğŸš€ Starting K-RagRec Pipeline for '{target_movie}'...")
    
    if target_movie not in movie_centroids:
        print("âŒ Movie not found.")
        return

    # 1. Retrieval (Semantic Search)
    print("ğŸ” 1. Semantic Retrieval (Vector Search)...")
    q_vec = movie_centroids[target_movie].reshape(1, -1).astype(np.float32)
    faiss.normalize_L2(q_vec)
    D, I = index.search(q_vec, k=4) # Top 3 candidates (excluding self)
    
    candidates = []
    for idx in I[0]:
        title = movie_titles[idx]
        if title != target_movie:
            candidates.append(title)
            
    # 2. Knowledge Sub-graph Retrieval (Real-time Graph Query)
    print("ğŸ•¸ï¸ 2. Knowledge Sub-graph Retrieval (Neo4j Query)...")
    driver = GraphDatabase.driver(URI, auth=AUTH)
    subgraphs = retrieve_knowledge_subgraph(driver, target_movie, candidates)
    driver.close()
    
    # 3. LLM Reasoning & Generation
    print("ğŸ¤– 3. Knowledge-Augmented Generation (LLM Inference)...")
    final_report = generate_recommendation_with_llm(target_movie, subgraphs)
    
    end_time = time.time()
    print("\n=== âœ¨ K-RagRec Recommendation Result âœ¨ ===")
    print(final_report)
    print(f"\nâ±ï¸ Total Execution Time: {end_time - start_time:.4f} sec")


if __name__ == "__main__":
    run_k_rag_rec("Aftersun 2022")
